{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":38556,"status":"ok","timestamp":1719600090626,"user":{"displayName":"Soham Badgujar","userId":"02971747036432404398"},"user_tz":-330},"id":"4YsNhgjiT7pO","outputId":"51a5eae4-aa65-437a-990e-d244de8c54b3"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":48401,"status":"ok","timestamp":1719601327880,"user":{"displayName":"Soham Badgujar","userId":"02971747036432404398"},"user_tz":-330},"id":"ulxvUDzY9nQ2","outputId":"49cbf545-ebdf-4205-8d50-c59f5755ee0f"},"outputs":[{"output_type":"stream","name":"stderr","text":["WARNING:absl:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n","WARNING:absl:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n","/usr/local/lib/python3.10/dist-packages/keras/src/saving/saving_lib.py:576: UserWarning: Skipping variable loading for optimizer 'adam', because it has 10 variables whereas the saved optimizer has 14 variables. \n","  saveable.load_own_variables(weights_store.get(inner_path))\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step\n","Day/Night model output: [1.7539445e-14]\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step\n","Fog model output: [0.00080445]\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step\n","Multi-label model output: [0.04477 0.6353  0.249   0.05624]\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n","Skyfall model output: [0.3406 0.4602 0.1763]\n","Combined Result: {'day': '0.00%', 'night': '16.67%', 'fog': '0.01%', 'clear': '16.65%', 'Sandstrom': '1.51%', 'Sunny': '27.50%', 'Thunderstrom': '8.42%', 'Tornado': '1.90%', 'Rain': '11.62%', 'Snow': '15.70%'}\n","Final Prediction: Sunny\n"]}],"source":["\n","import tensorflow.keras.losses as losses\n","import tensorflow.keras.optimizers as optimizers\n","from tensorflow.keras.models import load_model\n","import numpy as np\n","from PIL import Image\n","\n","# Example weights for each model\n","weights = {\n","    \"DayNightSense\": 1/8,\n","    \"FogVision\": 1/8,\n","    \"MultiLabelModel\": 2/8,  # Adjusted weight for the multi-label model\n","    \"Skyfall\": 2/8  # Adjusted weight for the new multi-label model\n","}\n","\n","# Placeholder for combined result categories\n","categories = [\"day\", \"night\", \"fog\", \"clear\", \"Sandstrom\", \"Sunny\", \"Thunderstrom\", \"Tornado\", \"Rain\", \"Snow\", \"Sunny\"]\n","\n","# Load and compile each model\n","day_night_model = load_model(\n","    '/content/drive/MyDrive/Final_Year_Weather_Classification/CNN_Resuidal_Code/Entire_CNN_DayNight_BinaryModel.h5',\n","    compile=True\n",")\n","day_night_model.compile(\n","    optimizer=optimizers.Adam(),\n","    loss=losses.BinaryCrossentropy(),\n","    metrics=['accuracy']\n",")\n","\n","fog_model = load_model(\n","    '/content/drive/MyDrive/Final_Year_Weather_Classification/CNN_Resuidal_Code/Entire_CNN_FogNet_BinaryModel.h5',\n","    compile=True\n",")\n","fog_model.compile(\n","    optimizer=optimizers.Adam(),\n","    loss=losses.BinaryCrossentropy(),\n","    metrics=['accuracy']\n",")\n","\n","multi_label_model = load_model(\n","    '/content/drive/MyDrive/Final_Year_Weather_Classification/CNN_Resuidal_Code/My_Strom_Vision.keras',\n","    compile=True\n",")\n","multi_label_model.compile(\n","    optimizer=optimizers.Adam(),\n","    loss=losses.BinaryCrossentropy(),\n","    metrics=['accuracy']\n",")\n","\n","skyfall_model = load_model(\n","    '/content/drive/MyDrive/Final_Year_Weather_Classification/CNN_Resuidal_Code/My_SkyFall.keras',\n","    compile=True\n",")\n","skyfall_model.compile(\n","    optimizer=optimizers.Adam(),\n","    loss=losses.BinaryCrossentropy(),\n","    metrics=['accuracy']\n",")\n","\n","# Function to normalize model outputs to sum to 1\n","def normalize(probs):\n","    total = sum(probs.values())\n","    return {k: v / total for k, v in probs.items()}\n","\n","# Function to get predictions from each model\n","def get_predictions(image, threshold=0.5):\n","    # Get day/night prediction\n","    day_night_probs = day_night_model.predict(image)[0]\n","    print(f\"Day/Night model output: {day_night_probs}\")\n","    day_night_result = {\"day\": day_night_probs[0] * 100, \"night\": (1 - day_night_probs[0]) * 100}\n","\n","    # Get fog prediction\n","    fog_probs = fog_model.predict(image)[0]\n","    print(f\"Fog model output: {fog_probs}\")\n","    fog_result = {\"fog\": fog_probs[0] * 100, \"clear\": (1 - fog_probs[0]) * 100}\n","\n","    # Get multi-label predictions\n","    multi_label_probs = multi_label_model.predict(image)[0]\n","    print(f\"Multi-label model output: {multi_label_probs}\")\n","    multi_label_result = {\n","        \"Sandstrom\": multi_label_probs[0] * 100,\n","        \"Sunny\": multi_label_probs[1] * 100,\n","        \"Thunderstrom\": multi_label_probs[2] * 100,\n","        \"Tornado\": multi_label_probs[3] * 100\n","    }\n","\n","    # Get Skyfall predictions\n","    skyfall_probs = skyfall_model.predict(image)[0]\n","    print(f\"Skyfall model output: {skyfall_probs}\")\n","    skyfall_result = {\n","        \"Rain\": skyfall_probs[0] * 100,\n","        \"Snow\": skyfall_probs[1] * 100,\n","        \"Sunny\": skyfall_probs[2] * 100\n","    }\n","\n","    model_outputs = {\n","        \"DayNightSense\": day_night_result,\n","        \"FogVision\": fog_result,\n","        \"MultiLabelModel\": multi_label_result,\n","        \"Skyfall\": skyfall_result\n","    }\n","\n","    return model_outputs\n","\n","# Function to combine model outputs\n","def combine_model_outputs(model_outputs, weights):\n","    combined_result = {category: 0 for category in categories}\n","\n","    for model, output in model_outputs.items():\n","        normalized_output = normalize(output)\n","        for condition, score in normalized_output.items():\n","            combined_result[condition] += weights[model] * score\n","\n","    # Normalize the combined result\n","    total_weight = sum(weights.values())\n","    combined_result = {condition: score / total_weight for condition, score in combined_result.items()}\n","\n","    # Convert combined result to percentages\n","    combined_result = {condition: score * 100 for condition, score in combined_result.items()}\n","\n","    # Determine final prediction\n","    final_prediction = max(combined_result, key=combined_result.get)\n","\n","    return combined_result, final_prediction\n","\n","# Function to load and preprocess the image\n","def load_and_preprocess_image(image_path):\n","    image = Image.open(image_path)\n","    # Convert to RGB if image has an alpha channel\n","    if image.mode == 'RGBA':\n","        image = image.convert('RGB')\n","    image = image.resize((224, 224))  # Resize to match the input size expected by your models\n","    image = np.array(image) / 255.0   # Normalize the image\n","    image = np.expand_dims(image, axis=0)  # Add batch dimension\n","    return image\n","\n","# Example usage\n","image_path = '/content/drive/MyDrive/Final_Year_Weather_Classification/Dataset/SkyFall/Snow/Screenshot (246).png'\n","image = load_and_preprocess_image(image_path)\n","\n","model_outputs = get_predictions(image)\n","combined_result, final_prediction = combine_model_outputs(model_outputs, weights)\n","\n","print(\"Combined Result:\", {k: f\"{v:.2f}%\" for k, v in combined_result.items()})\n","print(\"Final Prediction:\", final_prediction)"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":92635,"status":"ok","timestamp":1719600249055,"user":{"displayName":"Soham Badgujar","userId":"02971747036432404398"},"user_tz":-330},"id":"SzH2cxMs1SeZ","outputId":"bb5f05f2-61e3-4ca8-f8f9-2fb4def448c0"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (2.15.0)\n","Collecting tensorflow\n","  Downloading tensorflow-2.16.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (589.8 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m589.8/589.8 MB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.4.0)\n","Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)\n","Requirement already satisfied: flatbuffers>=23.5.26 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.3.25)\n","Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.5.4)\n","Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n","Collecting h5py>=3.10.0 (from tensorflow)\n","  Downloading h5py-3.11.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.3/5.3 MB\u001b[0m \u001b[31m64.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (18.1.1)\n","Collecting ml-dtypes~=0.3.1 (from tensorflow)\n","  Downloading ml_dtypes-0.3.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.2 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m65.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.3.0)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.1)\n","Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.20.3)\n","Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.31.0)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow) (67.7.2)\n","Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n","Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.4.0)\n","Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.12.2)\n","Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.14.1)\n","Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.64.1)\n","Collecting tensorboard<2.17,>=2.16 (from tensorflow)\n","  Downloading tensorboard-2.16.2-py3-none-any.whl (5.5 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m66.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting keras>=3.0.0 (from tensorflow)\n","  Downloading keras-3.4.1-py3-none-any.whl (1.1 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m57.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.37.0)\n","Requirement already satisfied: numpy<2.0.0,>=1.23.5 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.25.2)\n","Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow) (0.43.0)\n","Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from keras>=3.0.0->tensorflow) (13.7.1)\n","Collecting namex (from keras>=3.0.0->tensorflow)\n","  Downloading namex-0.0.8-py3-none-any.whl (5.8 kB)\n","Collecting optree (from keras>=3.0.0->tensorflow)\n","  Downloading optree-0.11.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (311 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m311.2/311.2 kB\u001b[0m \u001b[31m29.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.7)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (2024.6.2)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.17,>=2.16->tensorflow) (3.6)\n","Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.17,>=2.16->tensorflow) (0.7.2)\n","Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.17,>=2.16->tensorflow) (3.0.3)\n","Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.17,>=2.16->tensorflow) (2.1.5)\n","Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.0.0->tensorflow) (3.0.0)\n","Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.0.0->tensorflow) (2.16.1)\n","Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.0.0->tensorflow) (0.1.2)\n","Installing collected packages: namex, optree, ml-dtypes, h5py, tensorboard, keras, tensorflow\n","  Attempting uninstall: ml-dtypes\n","    Found existing installation: ml-dtypes 0.2.0\n","    Uninstalling ml-dtypes-0.2.0:\n","      Successfully uninstalled ml-dtypes-0.2.0\n","  Attempting uninstall: h5py\n","    Found existing installation: h5py 3.9.0\n","    Uninstalling h5py-3.9.0:\n","      Successfully uninstalled h5py-3.9.0\n","  Attempting uninstall: tensorboard\n","    Found existing installation: tensorboard 2.15.2\n","    Uninstalling tensorboard-2.15.2:\n","      Successfully uninstalled tensorboard-2.15.2\n","  Attempting uninstall: keras\n","    Found existing installation: keras 2.15.0\n","    Uninstalling keras-2.15.0:\n","      Successfully uninstalled keras-2.15.0\n","  Attempting uninstall: tensorflow\n","    Found existing installation: tensorflow 2.15.0\n","    Uninstalling tensorflow-2.15.0:\n","      Successfully uninstalled tensorflow-2.15.0\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","tf-keras 2.15.1 requires tensorflow<2.16,>=2.15, but you have tensorflow 2.16.1 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed h5py-3.11.0 keras-3.4.1 ml-dtypes-0.3.2 namex-0.0.8 optree-0.11.0 tensorboard-2.16.2 tensorflow-2.16.1\n"]}],"source":["!pip install --upgrade tensorflow\n","\n","import tensorflow.keras.losses as losses\n","import tensorflow.keras.optimizers as optimizers\n","from tensorflow.keras.models import load_model\n","import numpy as np\n","from PIL import Image\n","\n","# ... rest of your code ..."]},{"cell_type":"code","execution_count":3,"metadata":{"executionInfo":{"elapsed":15,"status":"ok","timestamp":1719600249056,"user":{"displayName":"Soham Badgujar","userId":"02971747036432404398"},"user_tz":-330},"id":"ZcUDLzKS3H5k"},"outputs":[],"source":["# Function to load and preprocess the image\n","def load_and_preprocess_image(image_path):\n","    image = Image.open(image_path).convert('RGB') # Convert image to RGB format\n","    image = image.resize((224, 224))  # Resize to match the input size expected by your models\n","    image = np.array(image) / 255.0   # Normalize the image\n","    image = np.expand_dims(image, axis=0)  # Add batch dimension\n","    return image"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":11200,"status":"ok","timestamp":1719600260242,"user":{"displayName":"Soham Badgujar","userId":"02971747036432404398"},"user_tz":-330},"id":"WyO12EgxXoBv","outputId":"31b2ab55-e707-489a-9da1-b1cde4202da5"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: h5py in /usr/local/lib/python3.10/dist-packages (3.11.0)\n","Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.10/dist-packages (from h5py) (1.25.2)\n","<KeysViewHDF5 ['conv1_bn', 'conv1_conv', 'conv1_pad', 'conv1_relu', 'conv2_block1_0_bn', 'conv2_block1_0_conv', 'conv2_block1_1_bn', 'conv2_block1_1_conv', 'conv2_block1_1_relu', 'conv2_block1_2_bn', 'conv2_block1_2_conv', 'conv2_block1_2_relu', 'conv2_block1_3_bn', 'conv2_block1_3_conv', 'conv2_block1_add', 'conv2_block1_out', 'conv2_block2_1_bn', 'conv2_block2_1_conv', 'conv2_block2_1_relu', 'conv2_block2_2_bn', 'conv2_block2_2_conv', 'conv2_block2_2_relu', 'conv2_block2_3_bn', 'conv2_block2_3_conv', 'conv2_block2_add', 'conv2_block2_out', 'conv2_block3_1_bn', 'conv2_block3_1_conv', 'conv2_block3_1_relu', 'conv2_block3_2_bn', 'conv2_block3_2_conv', 'conv2_block3_2_relu', 'conv2_block3_3_bn', 'conv2_block3_3_conv', 'conv2_block3_add', 'conv2_block3_out', 'conv3_block1_0_bn', 'conv3_block1_0_conv', 'conv3_block1_1_bn', 'conv3_block1_1_conv', 'conv3_block1_1_relu', 'conv3_block1_2_bn', 'conv3_block1_2_conv', 'conv3_block1_2_relu', 'conv3_block1_3_bn', 'conv3_block1_3_conv', 'conv3_block1_add', 'conv3_block1_out', 'conv3_block2_1_bn', 'conv3_block2_1_conv', 'conv3_block2_1_relu', 'conv3_block2_2_bn', 'conv3_block2_2_conv', 'conv3_block2_2_relu', 'conv3_block2_3_bn', 'conv3_block2_3_conv', 'conv3_block2_add', 'conv3_block2_out', 'conv3_block3_1_bn', 'conv3_block3_1_conv', 'conv3_block3_1_relu', 'conv3_block3_2_bn', 'conv3_block3_2_conv', 'conv3_block3_2_relu', 'conv3_block3_3_bn', 'conv3_block3_3_conv', 'conv3_block3_add', 'conv3_block3_out', 'conv3_block4_1_bn', 'conv3_block4_1_conv', 'conv3_block4_1_relu', 'conv3_block4_2_bn', 'conv3_block4_2_conv', 'conv3_block4_2_relu', 'conv3_block4_3_bn', 'conv3_block4_3_conv', 'conv3_block4_add', 'conv3_block4_out', 'conv4_block1_0_bn', 'conv4_block1_0_conv', 'conv4_block1_1_bn', 'conv4_block1_1_conv', 'conv4_block1_1_relu', 'conv4_block1_2_bn', 'conv4_block1_2_conv', 'conv4_block1_2_relu', 'conv4_block1_3_bn', 'conv4_block1_3_conv', 'conv4_block1_add', 'conv4_block1_out', 'conv4_block2_1_bn', 'conv4_block2_1_conv', 'conv4_block2_1_relu', 'conv4_block2_2_bn', 'conv4_block2_2_conv', 'conv4_block2_2_relu', 'conv4_block2_3_bn', 'conv4_block2_3_conv', 'conv4_block2_add', 'conv4_block2_out', 'conv4_block3_1_bn', 'conv4_block3_1_conv', 'conv4_block3_1_relu', 'conv4_block3_2_bn', 'conv4_block3_2_conv', 'conv4_block3_2_relu', 'conv4_block3_3_bn', 'conv4_block3_3_conv', 'conv4_block3_add', 'conv4_block3_out', 'conv4_block4_1_bn', 'conv4_block4_1_conv', 'conv4_block4_1_relu', 'conv4_block4_2_bn', 'conv4_block4_2_conv', 'conv4_block4_2_relu', 'conv4_block4_3_bn', 'conv4_block4_3_conv', 'conv4_block4_add', 'conv4_block4_out', 'conv4_block5_1_bn', 'conv4_block5_1_conv', 'conv4_block5_1_relu', 'conv4_block5_2_bn', 'conv4_block5_2_conv', 'conv4_block5_2_relu', 'conv4_block5_3_bn', 'conv4_block5_3_conv', 'conv4_block5_add', 'conv4_block5_out', 'conv4_block6_1_bn', 'conv4_block6_1_conv', 'conv4_block6_1_relu', 'conv4_block6_2_bn', 'conv4_block6_2_conv', 'conv4_block6_2_relu', 'conv4_block6_3_bn', 'conv4_block6_3_conv', 'conv4_block6_add', 'conv4_block6_out', 'conv5_block1_0_bn', 'conv5_block1_0_conv', 'conv5_block1_1_bn', 'conv5_block1_1_conv', 'conv5_block1_1_relu', 'conv5_block1_2_bn', 'conv5_block1_2_conv', 'conv5_block1_2_relu', 'conv5_block1_3_bn', 'conv5_block1_3_conv', 'conv5_block1_add', 'conv5_block1_out', 'conv5_block2_1_bn', 'conv5_block2_1_conv', 'conv5_block2_1_relu', 'conv5_block2_2_bn', 'conv5_block2_2_conv', 'conv5_block2_2_relu', 'conv5_block2_3_bn', 'conv5_block2_3_conv', 'conv5_block2_add', 'conv5_block2_out', 'conv5_block3_1_bn', 'conv5_block3_1_conv', 'conv5_block3_1_relu', 'conv5_block3_2_bn', 'conv5_block3_2_conv', 'conv5_block3_2_relu', 'conv5_block3_3_bn', 'conv5_block3_3_conv', 'conv5_block3_add', 'conv5_block3_out', 'dense', 'dense_1', 'flatten', 'input_1', 'pool1_pad', 'pool1_pool', 'top_level_model_weights']>\n"]}],"source":["!pip install h5py\n","import h5py\n","\n","# Open the HDF5 file\n","with h5py.File('/content/drive/MyDrive/Final_Year_Weather_Classification/CNN_Resuidal_Code/CNN_DayNight_BinaryModel150ep.h5', 'r') as f:\n","    # Print the keys (contents) of the file\n","    print(f.keys())"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[{"file_id":"15l4Wj0-cCQQbjyhlemiV7_n4J2unLitj","timestamp":1702536201578}]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}